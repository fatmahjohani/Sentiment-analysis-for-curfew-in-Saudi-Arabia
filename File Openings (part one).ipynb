{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "\n",
    "\n",
    "# Capstone : Sentiment analysis for curfew in Saudi Arabia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Group Member:\n",
    "\n",
    "\n",
    "- Fatimah Aljohani\n",
    "- Rawan Almalki\n",
    "- Najwa Alharbi\n",
    "\n",
    "<img src=\"https://www.al-khaleeg.com/wp-content/uploads/2020/04/IMG-20200420-WA0157.jpg\" style=\"height: 350px; width: 900px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyarabic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tashaphyne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarabic.araby as araby\n",
    "import pyarabic.number as number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n",
    "import statsmodels.api as sm  \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Notebook we are openenig the json file for each day (we have 4 months Jan, Feb, March and April) and combined all the Tweets in one dataframe at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jan 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Openeing the files for all the days in Jan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 1\n",
    "tweet_j1= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-01.jsonl', encoding='utf-8',lines=True)\n",
    "#encoding='utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 2\n",
    "tweet_j2= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-02.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 3\n",
    "tweet_j3= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-03.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 4\n",
    "tweet_j4= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-04.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 5\n",
    "tweet_j5= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-05.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 6\n",
    "tweet_j6= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-06.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 7\n",
    "tweet_j7= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-07.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 8\n",
    "tweet_j8= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-08.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 9\n",
    "tweet_j9= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-09.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 10\n",
    "tweet_j10= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-10.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 11\n",
    "tweet_j11= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-11.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 12\n",
    "tweet_j12= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-12.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 13\n",
    "tweet_j13= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-13.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 14\n",
    "tweet_j14= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-14.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 15\n",
    "tweet_j15= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-15.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 16\n",
    "tweet_j16= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-16.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 17\n",
    "tweet_j17= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-17.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 18\n",
    "tweet_j18= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-18.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 19\n",
    "tweet_j19= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-19.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 20\n",
    "tweet_j20= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-20.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 21\n",
    "tweet_j21= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-21.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 22\n",
    "tweet_j22= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-22.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 23\n",
    "tweet_j23= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-23.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 24\n",
    "tweet_j24= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-24.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 25\n",
    "tweet_j25= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-25.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 26\n",
    "tweet_j26= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-26.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 27\n",
    "tweet_j27= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-27.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 28\n",
    "tweet_j28= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-28.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 29\n",
    "tweet_j29= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-29.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 30\n",
    "tweet_j30= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-30.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jan 31\n",
    "tweet_j31= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\01-2020\\coronavirus-tweet-id-2020-01-31.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all the days in Jan into one dataframe \n",
    "tweet_jan= pd.concat([tweet_j1,tweet_j2,tweet_j3,tweet_j4,tweet_j5,tweet_j6,\n",
    "                      tweet_j7,tweet_j8,tweet_j9,tweet_j10,tweet_j11,tweet_j12,\n",
    "                      tweet_j13,tweet_j14,tweet_j15,tweet_j16,tweet_j17,tweet_j18,\n",
    "                      tweet_j19,tweet_j20,tweet_j21,tweet_j22,tweet_j23,tweet_j24,\n",
    "                      tweet_j25,tweet_j26,tweet_j27,tweet_j28,tweet_j29,tweet_j30,\n",
    "                      tweet_j31], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know the shape of the Jan dataframe \n",
    "tweet_jan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe into a csv file \n",
    "\n",
    "# we save the file and store it in datasets file so we comments this code in order to not save the file in your laptop and the path will change\n",
    "\n",
    "\n",
    "# tweet_jan.to_csv('df_jan.csv',index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (28,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# opning the Jan dataframe \n",
    "\n",
    "df_jan = pd.read_csv('datasets/jan/df_jan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feb 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The files are getting larger so we open the files using chinks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Openeing the files for all the days in Feb \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Feb 1\n",
    "\n",
    "chunksize = 20000 # divided the data into every 20000 \n",
    "batch_no=1\n",
    "for chunk_f1 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-01.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f1.to_json('chunk_f1' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f1.to_csv('tweet_f1.csv',index = False) # save the file into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 2\n",
    "\n",
    "for chunk_f2 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-02.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f2.to_json('chunk_f2' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f2.to_csv('tweet_f2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 3\n",
    "\n",
    "for chunk_f3 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-03.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f3.to_json('chunk_f3' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f3.to_csv('tweet_f3.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 4\n",
    "\n",
    "for chunk_f4 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-04.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f4.to_json('chunk_f4' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f4.to_csv('tweet_f4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 5\n",
    "\n",
    "for chunk_f5 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-05.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f5.to_json('chunk_f5' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f5.to_csv('tweet_f5.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 6\n",
    "\n",
    "for chunk_f6 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-06.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f6.to_json('chunk_f6' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f6.to_csv('tweet_f6.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 7 \n",
    "\n",
    "for chunk_f7 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-07.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f7.to_json('chunk_f7' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f7.to_csv('tweet_f7.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 8\n",
    "\n",
    "for chunk_f8 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-08.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f8.to_json('chunk_f8' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f8.to_csv('tweet_f8.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 9\n",
    "\n",
    "for chunk_f9 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-09.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f9.to_json('chunk_f9' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f9.to_csv('tweet_f9.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 10\n",
    "\n",
    "for chunk_f10 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-10.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f10.to_json('chunk_f10' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f10.to_csv('tweet_f10.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 11\n",
    "\n",
    "for chunk_f11 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-11.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f11.to_json('chunk_f11' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f11.to_csv('tweet_f11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 12\n",
    "\n",
    "for chunk_f12 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-12.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f12.to_json('chunk_f12' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f12.to_csv('tweet_f12.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 13\n",
    "\n",
    "for chunk_f13 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-13.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f13.to_json('chunk_f13' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f13.to_csv('tweet_f13.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 14\n",
    "\n",
    "for chunk_f14 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-14.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f14.to_json('chunk_f14' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f14.to_csv('tweet_f14.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 15\n",
    "\n",
    "for chunk_f15 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-15.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f15.to_json('chunk_f15' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f15.to_csv('tweet_f15.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 16\n",
    "\n",
    "for chunk_f16 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-16.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f16.to_json('chunk_f16' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f16.to_csv('tweet_f16.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 17\n",
    "\n",
    "for chunk_f17 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-17.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f17.to_json('chunk_f17' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f17.to_csv('tweet_f17.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 18\n",
    "\n",
    "for chunk_f18 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-18.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f18.to_json('chunk_f18' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f18.to_csv('tweet_f18.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 19\n",
    "\n",
    "for chunk_f19 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-19.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f19.to_json('chunk_f19' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f19.to_csv('tweet_f19.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 20 \n",
    "\n",
    "for chunk_f20 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-20.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f20.to_json('chunk_f20' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f20.to_csv('tweet_f20.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 21\n",
    "\n",
    "for chunk_f21 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-21.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f21.to_json('chunk_f21' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f21.to_csv('tweet_f21.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 22\n",
    "\n",
    "for chunk_f22 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-22.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f22.to_json('chunk_f22' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f22.to_csv('tweet_f22.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 23\n",
    "\n",
    "for chunk_f23 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-23.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f23.to_json('chunk_f23' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f23.to_csv('tweet_f23.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 24\n",
    "\n",
    "for chunk_f24 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-24.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f24.to_json('chunk_f24' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f24.to_csv('tweet_f24.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 25\n",
    "\n",
    "for chunk_f25 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-25.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f25.to_json('chunk_f25' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f25.to_csv('tweet_f25.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 26\n",
    "\n",
    "for chunk_f26 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-26.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f26.to_json('chunk_f26' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f26.to_csv('tweet_f26.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 27\n",
    "\n",
    "for chunk_f27 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-27.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f27.to_json('chunk_f27' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f27.to_csv('tweet_f27.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 28\n",
    "\n",
    "for chunk_f28 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-28.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f28.to_json('chunk_f28' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f28.to_csv('tweet_f28.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feb 29\n",
    "\n",
    "for chunk_f29 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\02-2020\\coronavirus-tweet-id-2020-02-29.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_f29.to_json('chunk_f29' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_f29.to_csv('tweet_f29.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the files in order merged into one dataframe\n",
    "\n",
    "path = r'datasets/february-tweets'        # the path of the files            \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "df_feb   = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe into a csv file \n",
    "\n",
    "# we save the file and store it in datasets file so we comments this code in order to not save the file in your laptop and the path will change\n",
    "\n",
    "# df_feb.to_csv('df_feb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (1,9,28,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# open the Feb file\n",
    "\n",
    "df_feb = pd.read_csv('datasets/df_feb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## March 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Openeing the files for all the days in March \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 1\n",
    "\n",
    "tweet_m1= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-01.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m1.to_csv('tweet_m1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 2\n",
    "\n",
    "tweet_m2= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-02.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m2.to_csv('tweet_m2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 3\n",
    "\n",
    "tweet_m3= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-03.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m3.to_csv('tweet_m3.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 4\n",
    "\n",
    "tweet_m4= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-04.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m4.to_csv('tweet_m4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 5\n",
    "\n",
    "tweet_m5= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-05.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m5.to_csv('tweet_m5.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 6\n",
    "\n",
    "tweet_m6= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-06.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m6.to_csv('tweet_m6.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 7\n",
    "\n",
    "tweet_m7= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-07.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m7.to_csv('tweet_m7.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 8\n",
    "\n",
    "tweet_m8= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-08.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m8.to_csv('tweet_m8.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 9\n",
    "\n",
    "tweet_m9= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-09.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m9.to_csv('tweet_m9.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 10\n",
    "\n",
    "tweet_m10= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-10.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m10.to_csv('tweet_m10.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 11\n",
    "\n",
    "tweet_m11= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-11.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m11.to_csv('tweet_m11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 12\n",
    "\n",
    "tweet_m12= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-12.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m12.to_csv('tweet_m12.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 13\n",
    "\n",
    "tweet_m13= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-13.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m13.to_csv('tweet_m13.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 14\n",
    "\n",
    "tweet_m14= pd.read_json (r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-14.jsonl', encoding='utf-8',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m14.to_csv('tweet_m14.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 14\n",
    "\n",
    "df_chunk = pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-15.jsonl',\n",
    "                        encoding='utf-8', lines=True, chunksize=20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 15\n",
    "\n",
    "chunksize = 20000\n",
    "batch_no=1\n",
    "for chunk in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-15.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk.to_json('tweet_m15' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.to_csv('tweet_m15.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 16\n",
    "for chunk_m16 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-16.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m16.to_json('tweet_m16' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_m16.to_csv('tweet_m16.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 17\n",
    "\n",
    "for chunk_m17 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-17.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m17.to_json('tweet_m17' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.to_csv('tweet_m17.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 18\n",
    "\n",
    "for chunk_m18 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-18.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m18.to_json('chunk_m18' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m18.to_csv('tweet_m18.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 19\n",
    "\n",
    "\n",
    "for chunk_m19 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-19.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m19.to_json('chunk_m19' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m19.to_csv('tweet_m19.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 20\n",
    "\n",
    "\n",
    "for chunk_m20 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-20.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m20.to_json('chunk_m20' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m20.to_csv('tweet_m20.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 21\n",
    "\n",
    "for chunk_m21 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-21.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m21.to_json('chunk_m21' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m21.to_csv('tweet_m21.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 22\n",
    "\n",
    "for chunk_m22 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-22.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m22.to_json('chunk_m22' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m22.to_csv('tweet_m22.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 23\n",
    "\n",
    "for chunk_m23 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-23.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m23.to_json('chunk_m23' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m23.to_csv('tweet_m23.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 24\n",
    "\n",
    "for chunk_m24 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-24.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m24.to_json('chunk_m24' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m24.to_csv('tweet_m24.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 25\n",
    "\n",
    "for chunk_m25 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-25.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m25.to_json('chunk_m25' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m25.to_csv('tweet_m25.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 26\n",
    "\n",
    "for chunk_m26 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-26.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m26.to_json('chunk_m26' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m26.to_csv('tweet_m26.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 27\n",
    "for chunk_m27 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-27.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m27.to_json('chunk_m27' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m27.to_csv('tweet_m27.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 28\n",
    "\n",
    "for chunk_m28 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-28.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m28.to_json('chunk_m28' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m28.to_csv('tweet_m28.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 29\n",
    "\n",
    "for chunk_m29 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-29.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m29.to_json('chunk_m29' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m29.to_csv('tweet_m29.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 30\n",
    "\n",
    "for chunk_m30 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-30.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m30.to_json('chunk_m30' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m30.to_csv('tweet_m30.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# March 31\n",
    "\n",
    "for chunk_m31 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\03-2020\\coronavirus-tweet-id-2020-03-31.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_m31.to_json('chunk_m31' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_m31.to_csv('tweet_m31.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the files in order merged into one dataframe\n",
    "\n",
    "path = r'datasets/march-tweets'                     \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe into a csv file \n",
    "\n",
    "# we save the file and store it in datasets file so we comments this code in order to not save the file in your laptop and the path will change\n",
    "\n",
    "\n",
    "concatenated_df.to_csv('df_march.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march = pd.read_csv('datasets/df_march.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_march.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## April 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Openeing the files for all the days in April \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 1\n",
    "\n",
    "for chunk_a1 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-01.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a1.to_json('chunk_a1' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a1.to_csv('tweet_a1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 2\n",
    "\n",
    "for chunk_a2 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-02.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a2.to_json('chunk_a2' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a2.to_csv('tweet_a2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 3\n",
    "for chunk_a3 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-03.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a3.to_json('chunk_a3' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a3.to_csv('tweet_a3.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 4\n",
    "for chunk_a4 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-04.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a4.to_json('chunk_a4' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a4.to_csv('tweet_a4.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 5\n",
    "\n",
    "for chunk_a5 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-05.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a5.to_json('chunk_a5' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a5.to_csv('tweet_a5.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 6\n",
    "\n",
    "for chunk_a6 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-06.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a6.to_json('chunk_a6' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a6.to_csv('tweet_a6.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 7\n",
    "\n",
    "for chunk_a7 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-07.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a7.to_json('chunk_a7' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a7.to_csv('tweet_a7.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 8\n",
    "for chunk_a8 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-08.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a8.to_json('chunk_a8' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a8.to_csv('tweet_a8.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 9\n",
    "for chunk_a9 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-09.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a9.to_json('chunk_a9' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a9.to_csv('tweet_a9.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 10\n",
    "\n",
    "for chunk_a10 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-10.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a10.to_json('chunk_a10' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a10.to_csv('tweet_a10.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April 11\n",
    "\n",
    "for chunk_a11 in pd.read_json(r'Coronavirus-Public-Arabic-Twitter-Data-Set-master\\04-2020\\coronavirus-tweet-id-2020-04-11.jsonl',\n",
    "                          encoding='utf-8', lines=True, chunksize=chunksize):\n",
    "    chunk_a11.to_json('chunk_a11' + str(batch_no) + '.jsonl')\n",
    "    batch_no +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_a11.to_csv('tweet_a11.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# opening the files in order merged into one dataframe\n",
    "\n",
    "path = r'datasets/april-tweets'                    \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "april_df   = pd.concat(df_from_each_file, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "april_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe into a csv file \n",
    "\n",
    "# we save the file and store it in datasets file so we comments this code in order to not save the file in your laptop and the path will change\n",
    "\n",
    "\n",
    "# april_df.to_csv('df_april.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatma\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# open april tweet file\n",
    "\n",
    "df_april = pd.read_csv('datasets/df_april.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81183, 32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_april.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
